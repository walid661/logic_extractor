# Evaluation Harness

Outils d'Ã©valuation pour mesurer les performances du Logic Extractor.

## Utilisation

### 1. PrÃ©requis

```bash
# Variables d'environnement nÃ©cessaires
export SUPABASE_URL="https://your-project.supabase.co"
export SUPABASE_ANON_KEY="your-anon-key"
```

### 2. PrÃ©parer les fixtures

Placer des fichiers PDF de test dans `scripts/eval/fixtures/` :

```bash
cp /path/to/test-document.pdf scripts/eval/fixtures/
```

### 3. Lancer l'Ã©valuation

```bash
deno run --allow-net --allow-read --allow-env scripts/eval/measure-latency.ts
```

## MÃ©triques mesurÃ©es

### Actuellement implÃ©mentÃ© :
- â±ï¸ **Latence E2E** (p50, p95)
- ðŸ“ **Nombre de rÃ¨gles extraites**
- ðŸŽ¯ **Confiance moyenne**
- âœ… **Taux de succÃ¨s**

### Ã€ implÃ©menter (avec gold dataset) :
- **Precision** : rÃ¨gles correctes / rÃ¨gles extraites
- **Recall** : rÃ¨gles correctes / rÃ¨gles attendues
- **F1 Score** : moyenne harmonique de P et R
- **Cost** : Estimation coÃ»t OpenAI par document

## CrÃ©er un gold dataset

1. Annoter des documents de rÃ©fÃ©rence :
   ```bash
   # CrÃ©er un fichier JSON pour chaque document
   cat > fixtures/doc1.gold.json << EOF
   {
     "documentId": "doc1",
     "rules": [
       {
         "text": "Les remboursements doivent Ãªtre effectuÃ©s sous 30 jours",
         "domain": "Finance",
         "confidence": 0.95
       }
     ]
   }
   EOF
   ```

2. Modifier `measure-latency.ts` pour calculer P/R/F1

## Exemple de sortie

```
ðŸš€ Logic Extractor - Latency Evaluation Harness

============================================================

ðŸ“¦ Found 3 fixture(s) to process

ðŸ“„ Processing: contract-sample.pdf
  â³ Job ID: 123e4567-e89b-12d3-a456-426614174000
  ðŸ“Š Progress: 30% (running)
  ðŸ“Š Progress: 70% (running)
  ðŸ“Š Progress: 100% (done)
  âœ… Completed in 12.3s
  ðŸ“ Rules extracted: 45
  ðŸŽ¯ Avg confidence: 82.5%

============================================================
ðŸ“Š EVALUATION SUMMARY

âœ… Successful: 3/3
â±ï¸  Avg latency: 11.2s
ðŸ“ Total rules: 128
ðŸŽ¯ Avg confidence: 79.3%

ðŸ“ˆ Latency distribution:
   p50: 11.2s
   p95: 14.5s
============================================================

ðŸ’¡ Next steps:
   1. Annotate fixtures with ground truth rules
   2. Add P/R/F1 calculation
   3. Track cost per document
```
